# WING Reading Group (CS6101-1920)
### Fri 13:00-15:00 @ MR6 (AS6 #05-10)

<img title="Photo by Sarah Lee on Unsplash" alt="Photo by Sarah Lee on Unsplash" src="img/hisarahlee.png" class="img-fluid" style="float:left" height="150" /

Our reading group will be conducted as a group seminar, with class participants nominating themselves and presenting the materials and leading the discussion. 

<a href="http://cs6101.slack.com/">A mandatory discussion group is on Slack</a>. Students and guests, please login when you are free. If you have a @comp.nus.edu.sg, @u.nus.edu, @nus.edu.sg, @a-star.edu.sg, @dsi.a-star.edu.sg or @i2r.a-star.edu.sg. email address you can create your Slack account for the group discussion without needing an invite.

**For interested public participants**, please send Min an email at ```kanmy@comp.nus.edu.sg``` if you need an invite to the Slack group.  The Slack group is being reused from previous semesters.  Once you are in the Slack group, you can consider yourself registered for the course.

1. Embeddings
1. Pretraining 
1. Transformer and BERT 
2. Graph Based Models 
1. Multimodal Models
1. Recommendation Systems
1. Semantic Analysis
1. Text Summarization
1. Named Entity Recognition/ Information Extraction
1. Machine Reading Comprehension
1. Neural Machine Translation
1. Dialogue 
1. Entity Linking 
1. Knowledge Graph
1. Neural Question Generation

## People

Welcome. If you are an external visitor and would like to join us, please email Kan Min-Yen to be added to the class role. Guests from industry, schools and other far-reaching places in SG welcome, pending space and time logistic limitations. The more, the merrier.

External guests will be listed here in due course once the course has started. Please refer to our Slack after you have been invited for the most up-to-date information.

**External Guests**: _TBA_

## Schedule

<style type="text/css">
  td { padding:5px; }
</style>

<h2 id="schedule">Schedule</h2>

<table class="table table-striped">
<thead class="thead-inverse"><tr><th>Date</th><th width="60%">Description</th><th>Deadlines</th></tr></thead>
<tbody>
<tr>
  <td><b>Week 1</b><br />15 Aug
  </td>
  <td>
  <strong>
Motivation / Likelihood-based Models Part I: Autoregressive Models
  </strong>
<br />
  [&nbsp;«&nbsp;<a href="#" data-toggle="#div1">Recording&nbsp;@&nbsp;YouTube&nbsp;</a>&nbsp;]
<div id="div1" style="display:none">
  <iframe width="700" height="500" src="https://www.youtube.com/embed/i4Y5e9f2gcE" frameborder="0" allow="accelero\
meter; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</div>
  </td>
  <td>
  </td>
</tr>
<tr>
  <td><b>Week 2</b><br />22 Aug
  </td>
  <td>
  <strong>
Likelihood-based Models: Autoregressive Models / Flow Models
  </strong>
<br />
  [&nbsp;«&nbsp;<a href="#" data-toggle="#div2">Recording&nbsp;@&nbsp;YouTube&nbsp;</a>&nbsp;]
<div id="div2" style="display:none">
  <iframe width="700" height="500" src="https://www.youtube.com/embed/_jm5tdV3CXs" frameborder="0" allow="accelero\
meter; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</div>
  </td>
  <td>
  </td>
</tr>
<tr>
  <td><b>Week 3</b><br />29 Aug
  </td>
  <td><strong>
Lossless Compression / Flow Models
  </strong>
<br />
  [&nbsp;«&nbsp;<a href="#" data-toggle="#div3">Recording&nbsp;@&nbsp;YouTube&nbsp;</a>&nbsp;]
<div id="div3" style="display:none">
  <iframe width="700" height="500" src="https://www.youtube.com/embed/l9aX_tHJGek" frameborder="0" allow="accelero\
meter; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</div>
  </td>
  <td>
  </td>
</tr>
<tr>
  <td><b>Week 4</b><br />5 Sep
  </td>
  <td>
  <strong>
Lecture 3a: Likelihood-based Models Part II: Flow Models (ctd) (same slides as week 2) /
Lecture 3b: Latent Variable Models - part 1 
  </strong>
</td>
  <td>
</td>
</tr>
<tr>
  <td><b>Week 5</b><br />12 Sep
  </td>
  <td>
  <strong>
Lecture 4a: Latent Variable Models - part 2 /
Lecture 4b: Bits-Back Coding
  </strong>
  </td>
  <td>
  </td>
</tr>
<tr>
  <td><b>Week 6</b><br />19 Sep
  </td>
  <td>
  <strong>
Lecture 5a: Latent Variable Models - wrap-up (same slides as Latent Variable Models - part 2) /
Lecture 5b: ANS coding (same slides as bits-back coding) / 
Lecture 5c: Implicit Models / Generative Adversarial Networks
  </strong>
<td>Preliminary project titles and team members due on Slack's <code>#projects</code></td>
&lt;/tr&gt;
<tr>
  <td><b>Recess Week</b><br />26 Sep
  </td>
  <td>
  <strong>
Lecture 6a: Implicit Models / Generative Adversarial Networks (ctd) (same slides as 5c) /
Lecture 6b: Non-Generative Representation Learning [UPDATED 3/24]
  </strong>
</td>
  <td>
  </td>
</tr>
<tr>
  <td><b>Week 7</b><br />3 Oct
  </td>
  <td>
  <strong>
Lecture 7: Non-Generative Representation Learning (same slides as 6b)
  </strong>
</td>
  <td>Preliminary abstracts due to <code>#projects</code>
  </td>
</tr>
<tr>
  <td><b>Week 8</b><br />10 Oct
  </td>
  <td>
  <strong>
Lecture 8a: Strengths/Weaknesses of Unsupervised Learning Methods Covered Thus Far /
Lecture 8b: Semi-Supervised Learning /
Lecture 8c: Guest Lecture by Ilya Sutskever
  </strong>
  </td>
  <td>
  </td>
</tr>
<tr>
  <td><b>Week 9</b><br />17 Oct
  </td>
  <td>
  <strong>
Lecture 9a: Unsupervised Distribution Alignment /
Lecture 9b: Guest Lecture by Alyosha Efros
  </strong>
  </td>
  <td>
  </td>
</tr>
<tr>
  <td><b>Week 10</b><br />24 Oct
  </td>
  <td>
    <strong>
Lecture 10: Language Models (Alec Radford)
  </strong>
</td>
  <td>
  </td>
</tr>
<tr>
  <td><b>Week 11</b><br />31 Oct
  </td>
  <td>
<strong>
<em>No lecture due to the <a href="https://wing.comp.nus.edu.sg/~ssnlp/">Singapore Symposium on Natural Language Processing</a> (SSNLP '19).</em>
  </strong>
</td>
  <td>
  </td>
</tr>
<tr>
  <td><b>Week 12</b><br />7 Nov
  </td>
  <td>
  <strong>
Lecture 11: Representation Learning in Reinforcement Learning
  </strong>
  </td>
  <td>
  </td>
</tr>
<tr>
  <td><b>Week 13</b><br />14 Nov
  </td>
  <td>
  <strong>
  TBA
  </strong>
  </td>
  <td>Participation on evening of 15th STePS
  </td>
</tr>
</td></tr></tbody></table>
